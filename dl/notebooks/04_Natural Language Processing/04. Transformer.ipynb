{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "train_model = False  # 실제 훈련을 할 시 True 로 변경\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# capture는 주렁주렁 출력 보여주지 않게끔\n",
    "# Font 설치\n",
    "!brew tap homebrew/cask-fonts\n",
    "!brew install --cask font-nanum\n",
    "!fc-cache -fv\n",
    "!rm -rf ~/Library/Caches/matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc(\"font\", family=\"NanumBarunGothic\")\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현\n",
    "\n",
    "* encoder, decoder 의 self attention 을 수행하는 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### einops\n",
    "* 장점 : 텐서 변환을 매우 쉽게 이해하고 변환\n",
    "* 단점 : 디버깅 힘들고 속도 느리다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "# 차원 재배치\n",
    "x = torch.randn(2, 3, 4)\n",
    "y = rearrange(x, \"a b c -> c a b\")  # 차원의 이름을 임의로 지정할 수 있다\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원 나누기\n",
    "x = torch.randn(6, 4)\n",
    "y = rearrange(\n",
    "    x, \"(a b) c -> a b c\", a=2, b=3\n",
    ")  # x 의 첫 번쨰 차원이 a 와 b 로 이루어져 있다\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Head Attention (MHA) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MHA(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=512, n_heads=8):\n",
    "        \"\"\"\n",
    "        d_model : dimension of embedding vector\n",
    "        n_heads : num of heads in MHA\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Q, K, V 벡터를 위한 linear layer\n",
    "        self.fc_q = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        self.fc_k = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        self.fc_v = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "        # 최종 출력을 위한 linear layer\n",
    "        self.fc_o = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "        # scaling for attention score\n",
    "        self.scale = torch.sqrt(\n",
    "            torch.tensor(d_model / n_heads)\n",
    "        )  # GPU 에서의 연산을 위해 tensor 로 변환\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Q, K, V : embedding vector of each word, (batch_size, max_len, dim)\n",
    "        mask : mask for attention score (optional) => init as None\n",
    "        \"\"\"\n",
    "\n",
    "        # linear transformation on embedding vector\n",
    "        Q = self.fc_q(Q)\n",
    "        K = self.fc_k(K)\n",
    "        V = self.fc_v(V)\n",
    "\n",
    "        # MHA 를 위해 embedding dim 을 n_head 개로 분할\n",
    "        # ex. (32, 128, 512) -> (32, 8, 128, 64)\n",
    "        Q = rearrange(Q, \"N t (h dk) -> N h t dk\", h=self.n_heads)\n",
    "        K = rearrange(K, \"N t (h dk) -> N h t dk\", h=self.n_heads)\n",
    "        V = rearrange(V, \"N t (h dk) -> N h t dk\", h=self.n_heads)\n",
    "\n",
    "        # attention score before softmax\n",
    "        attention_score = (\n",
    "            Q @ K.transpose(-2, 1) / self.scale\n",
    "        )  # (N, h, t, d_k) @ (N, h, d_k, t) -> (N, h, t(Query 길이), t(Key 길이))\n",
    "\n",
    "        # masking on padding\n",
    "        if mask is not None:\n",
    "            attention_score[mask] = -1e10\n",
    "\n",
    "        # softmax on Key\n",
    "        energy = torch.softmax(attention_score, dim=-1)\n",
    "\n",
    "        attention = energy @ V  # (N, h, t, t) @ (N, h, t, dk) -> (N, h, t, dk)\n",
    "\n",
    "        # head 차원을 연결해서 원래의 차원으로 되돌리기\n",
    "        x = rearrange(attention, \"N h t dk -> N t (h dk)\")  # (N, h, t, dk) -> (N, t, D)\n",
    "\n",
    "        # 최종 출력값에 대해 linear transformation (모든 head 의 분석 결과를 종합)\n",
    "        x = self.fc_o(x)\n",
    "\n",
    "        return x, energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Network (FNN)\n",
    "* encoder, decoder 의 MHA 결과를 하나로 합쳐준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_model=512, d_ff=2048, drop_p=0.1\n",
    "    ):  # dropout : 차원 확장에 의한 overfitting 방지\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, mha_output):\n",
    "        out = self.linear(mha_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA - FFN 연결 과정, skip connection, LN\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, n_heads, drop_p):\n",
    "        \"\"\"\n",
    "        d_model : 임베딩 벡터 차원\n",
    "        d_ff : feed forward 은닉층 차원\n",
    "        n_heads : MHA head 갯수\n",
    "        drop_p : dropout 비율\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # MHA (Self Attention)\n",
    "        self.self_atten = MHA(d_model=d_model, n_heads=n_heads)\n",
    "\n",
    "        # MHA 에 대한 layer normalization\n",
    "        self.self_atten_LN = nn.LayerNorm(normalized_shape=d_model)\n",
    "\n",
    "        # feed forward network\n",
    "        self.FF = FeedForward(d_model=d_model, d_ff=d_ff, drop_p=drop_p)\n",
    "\n",
    "        # feed forward 출력에 대한 LN\n",
    "        self.FF_LN = nn.LayerNorm(normalized_shape=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "    def forward(self, x, enc_mask):\n",
    "        \"\"\"\n",
    "        x : input tensor (batch_size, seq_len, d_model)\n",
    "        enc_mask : input mask (batch_size, 1, seq_len)\n",
    "\n",
    "        return : encoder output, energy\n",
    "        \"\"\"\n",
    "\n",
    "        # MHA block\n",
    "        residual, atten_enc = self.self_atten(Q=x, K=x, V=x, mask=enc_mask)\n",
    "        residual = self.dropout(residual)\n",
    "\n",
    "        # Skip Connection & LN\n",
    "        encoder_self_attention_output = self.self_atten_LN(x + residual)\n",
    "\n",
    "        # FFN block\n",
    "        residual = self.FF(encoder_self_attention_output)\n",
    "        residual = self.dropout(residual)\n",
    "\n",
    "        # Skip Connection & LN\n",
    "        encoder_ffn_output = self.FF_LN(encoder_self_attention_output + residual)\n",
    "\n",
    "        return encoder_ffn_output, atten_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, input_embedding, max_len, n_layers, d_model, d_ff, n_heads, drop_p\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_embedding : 입력 임베딩 레이어 (nn.Embedding)\n",
    "        max_len : input sequence 의 최대 길이 (int)\n",
    "        n_layers : encoder layer 의 개수\n",
    "        d_model : embedding vector 의 차원\n",
    "        d_ff : feed forward의 은닉층의 차원\n",
    "        n_heads : MHA의 head 개수\n",
    "        drop_p : dropout 비율\n",
    "        \"\"\"\n",
    "\n",
    "        # d_model 의 제곱근 값으로 scale -> embedding vector 크기 조정\n",
    "        self.scale = torch.sqrt(torch.tensor(d_model))\n",
    "\n",
    "        # input embedding layer\n",
    "        self.input_embedding = input_embedding\n",
    "\n",
    "        # 위치 embedding layer : 위치 정보를 학습하기 위한 layer\n",
    "        self.pos_embedding = nn.Embedding(num_embeddings=max_len, embedding_dim=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "        # 여러 개의 encoder layer 를 쌓기 위해 ModuleList 활용\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, d_ff, n_heads, drop_p) for _ in range(n_layers)]\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, mask, atten_map_save=False):\n",
    "        \"\"\"\n",
    "        src : input sequence (batch_size, seq_len)\n",
    "        mask : mask for padding (batch_size, 1, seq_len)\n",
    "        atten_map_save : attention map 을 저장할지 여부\n",
    "        \"\"\"\n",
    "        # 위치 index tensor 생성 : 각 batch 에서 sequence 길이만큼 위치 index 반복\n",
    "        pos = torch.arange(src.shape[1]).repeat(src.shape[0], 1).to(self.device)\n",
    "\n",
    "        # input embedding 과 위치 embedding 을 합해 input tensor 생성\n",
    "        x_embedding = self.input_embedding(src) + self.pos_embedding(pos)\n",
    "\n",
    "        x_embedding = self.dropout(x_embedding)\n",
    "\n",
    "        # 첫 입력\n",
    "        encoder_output = x_embedding\n",
    "\n",
    "        # energy 를 저장할 텐서\n",
    "        atten_encs = torch.tensor([]).to(self.device)\n",
    "\n",
    "        # 각 encoder layer 를 순차적으로 통과\n",
    "        for layer in self.layers:\n",
    "            encoder_output, atten_enc = layer(encoder_output, mask)\n",
    "\n",
    "            if atten_map_save:\n",
    "                atten_encs = torch.cat([atten_encs, atten_enc[0].unsqueeze()])\n",
    "\n",
    "        return encoder_output, atten_encs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "* masking 동작 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== attention_score에 마스킹 적용 전 ====================\n",
      "attention_score[0, 0] (첫 번째 배치, 첫 번째 헤드):\n",
      " tensor([[-0.5183, -2.0596,  0.6506, -1.5504,  0.3827, -0.7270,  1.2109, -0.6951,\n",
      "         -0.5891, -0.2788],\n",
      "        [-0.2571, -1.0110, -0.1957,  0.8078, -0.3465,  1.5329, -0.2836,  0.0332,\n",
      "         -0.9639,  1.8615],\n",
      "        [-0.8938,  1.2226, -2.6726,  0.2633,  2.5465, -1.2855, -0.7340, -0.8663,\n",
      "          1.1198, -1.6744],\n",
      "        [ 0.1153,  0.4407,  0.8844,  0.8611,  0.3045,  1.2003, -0.3898, -0.1153,\n",
      "          0.7977,  1.1075],\n",
      "        [-0.0661,  0.7321, -0.9453, -0.7476,  0.5816, -0.9432, -2.0681,  0.6070,\n",
      "          1.0032, -0.3740],\n",
      "        [ 0.5821, -0.5657,  0.6487,  0.5158, -0.2460,  0.1924, -0.8505,  1.8835,\n",
      "         -1.7205, -1.1974],\n",
      "        [ 0.1877, -0.4290,  0.7543,  0.8117,  0.4601, -0.2441, -0.4301,  0.6675,\n",
      "         -0.8089, -1.3165],\n",
      "        [ 0.5779,  0.2352,  0.7156,  0.9210, -1.8506,  0.3787,  1.4424, -0.7458,\n",
      "         -1.3133,  0.6149],\n",
      "        [-1.7010,  1.4378,  0.6148,  0.7725,  0.1391,  1.6369,  1.0610,  0.5145,\n",
      "         -1.6999, -1.1919],\n",
      "        [ 1.8165, -0.3138,  1.7138,  1.8104,  0.3882, -0.0269,  0.4168,  0.6030,\n",
      "          1.4808, -0.2951]])\n",
      "==================== attention_score에 마스킹 적용 전 ====================\n",
      "attention_score shape: torch.Size([3, 8, 10, 10])\n",
      "torch.Size([3, 8, 10, 10])\n",
      "==================== attention_score에 마스킹 적용 후 ====================\n",
      "attention_score[0, 0] (첫 번째 배치, 첫 번째 헤드):\n",
      " tensor([[-0.5183, -2.0596,  0.6506, -1.5504,  0.3827, -0.7270,  1.2109,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.2571, -1.0110, -0.1957,  0.8078, -0.3465,  1.5329, -0.2836,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.8938,  1.2226, -2.6726,  0.2633,  2.5465, -1.2855, -0.7340,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1153,  0.4407,  0.8844,  0.8611,  0.3045,  1.2003, -0.3898,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0661,  0.7321, -0.9453, -0.7476,  0.5816, -0.9432, -2.0681,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.5821, -0.5657,  0.6487,  0.5158, -0.2460,  0.1924, -0.8505,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1877, -0.4290,  0.7543,  0.8117,  0.4601, -0.2441, -0.4301,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.5779,  0.2352,  0.7156,  0.9210, -1.8506,  0.3787,  1.4424,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-1.7010,  1.4378,  0.6148,  0.7725,  0.1391,  1.6369,  1.0610,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 1.8165, -0.3138,  1.7138,  1.8104,  0.3882, -0.0269,  0.4168,  0.0000,\n",
      "          0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 예제 설정\n",
    "batch_size = 3\n",
    "seq_len = 10\n",
    "padding = 3\n",
    "n_heads = 8\n",
    "\n",
    "# attention_score 텐서 생성 (무작위 값으로 초기화)\n",
    "# Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "attention_score = torch.randn(batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "# enc_mask 생성: 패딩이 있는 위치를 마스킹\n",
    "# 각 시퀀스의 마지막 3개 위치에 패딩이 있다고 가정합니다.\n",
    "enc_mask = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],  # 첫 번째 시퀀스\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],  # 두 번째 시퀀스\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],  # 세 번째 시퀀스\n",
    "        ],\n",
    "        dtype=torch.bool,\n",
    "    )\n",
    "    .unsqueeze(1)\n",
    "    .unsqueeze(2)\n",
    ")  # Shape: (batch_size, 1, 1, seq_len)\n",
    "\n",
    "# enc_mask의 shape을 (batch_size, n_heads, seq_len, seq_len)로 확장\n",
    "enc_mask = enc_mask.expand(batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "print(\"=\" * 20, \"attention_score에 마스킹 적용 전\", \"=\" * 20)\n",
    "print(\"attention_score[0, 0] (첫 번째 배치, 첫 번째 헤드):\\n\", attention_score[0, 0])\n",
    "\n",
    "# attention_score에 enc_mask 적용\n",
    "if enc_mask is not None:\n",
    "    attention_score[enc_mask] = (\n",
    "        0  # 마스크된 위치에 매우 작은 값을 넣어 softmax 결과에 영향을 미치지 않도록 합니다.\n",
    "    )\n",
    "\n",
    "print(\"=\" * 20, \"attention_score에 마스킹 적용 전\", \"=\" * 20)\n",
    "print(\"attention_score shape:\", attention_score.shape)\n",
    "print(enc_mask.shape)\n",
    "\n",
    "# 이제 attention_score 텐서에서 마스크가 적용된 부분을 확인할 수 있습니다.\n",
    "# 특정 헤드에 대한 attention_score 확인 (예: 첫 번째 헤드)\n",
    "print(\"=\" * 20, \"attention_score에 마스킹 적용 후\", \"=\" * 20)\n",
    "print(\"attention_score[0, 0] (첫 번째 배치, 첫 번째 헤드):\\n\", attention_score[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        # self attention layer of decoder\n",
    "        self.self_attn = MHA(d_model, n_heads)\n",
    "        self.self_attn_LN = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Encoder - Decoder Attention layer\n",
    "        self.enc_dec_atten = MHA(d_model, n_heads)\n",
    "        self.enc_dec_atten_LN = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Feed Forward\n",
    "        self.FF = FeedForward(d_model, d_ff, drop_p)\n",
    "        self.FF_LN = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "    def forward(self, x, enc_out, dec_mask, enc_dec_mask):\n",
    "        \"\"\"\n",
    "        x : input tensor (batch_size, seq_len, d_model)\n",
    "        enc_out : output tensor (batch_size, seq_len, d_model)\n",
    "        dec_mask : mask for decoder self attention (batch_size, 1, seq_len)\n",
    "        enc_dec_mask : mask for encoder-decoder attention (batch_size, 1, seq_len)\n",
    "\n",
    "        return : output tensor, self attention map, encoder-decoder attention map\n",
    "        \"\"\"\n",
    "        # decoder self attention\n",
    "        residual, atten_dec = self.self_attn(Q=x, K=x, V=x, mask=dec_mask)\n",
    "        residual = self.dropout(residual)\n",
    "        decoder_masked_self_attention_output = self.self_attn_LN(x + residual)\n",
    "\n",
    "        # encoder-decoder attention\n",
    "        # Q : masked multi head attention\n",
    "        # K, V : encoder output\n",
    "        residual, atten_dec_enc = self.enc_dec_atten(\n",
    "            Q=decoder_masked_self_attention_output,\n",
    "            K=enc_out,\n",
    "            V=enc_out,\n",
    "            mask=enc_dec_mask,\n",
    "        )\n",
    "\n",
    "        residual = self.dropout(residual)\n",
    "        decoder_masked_self_attention_output = self.enc_dec_atten_LN(x + residual)\n",
    "\n",
    "        # feed forward\n",
    "        residual = self.FF(decoder_masked_self_attention_output)\n",
    "        residual = self.dropout(residual)\n",
    "        decoder_output = self.FF_LN(decoder_masked_self_attention_output + residual)\n",
    "\n",
    "        return decoder_output, atten_dec, atten_dec_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_embedding,\n",
    "        max_len,\n",
    "        n_layers,\n",
    "        d_model,\n",
    "        d_ff,\n",
    "        n_heads,\n",
    "        drop_p,\n",
    "        vocab_size,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_embedding : 입력 임베딩 레이어 (nn.Embedding)\n",
    "        max_len : input sequence 의 최대 길이 (int)\n",
    "        n_layers : encoder layer 의 개수\n",
    "        d_model : embedding vector 의 차원\n",
    "        d_ff : feed forward의 은닉층의 차원\n",
    "        n_heads : MHA의 head 개수\n",
    "        drop_p : dropout 비율\n",
    "        vocab_size : generator 를 만들기 위해 필요\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(d_model))\n",
    "\n",
    "        # input embedding layer\n",
    "        self.input_embedding = input_embedding\n",
    "\n",
    "        # position embedding layer\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, d_ff, n_heads, drop_p) for _ in range(n_layers)]\n",
    "        )\n",
    "\n",
    "        # Generator 구현\n",
    "        # decoder output vector 를 단어의 확률 분포로 변환\n",
    "        # decoder output vector 는 decoder layer 연산을 N 회 반복해 생성\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, target, enc_out, dec_mask, enc_dec_mask, atten_map_save=False):\n",
    "        # 위치 인덱스 텐서 생성: 각 배치에서 시퀀스 길이만큼 위치 인덱스를 반복\n",
    "        pos = (\n",
    "            torch.arange(target.shape[1]).repeat(target.shape[0], 1).to(self.device)\n",
    "        )  # (batch_size, seq_len)\n",
    "\n",
    "        # 입력 임베딩과 위치 임베딩을 합산하여 입력 텐서 x를 생성\n",
    "        # 입력 임베딩에 scale을 곱해 크기를 조정\n",
    "        y_embedding = self.scale * self.input_embedding(target) + self.pos_embedding(\n",
    "            pos\n",
    "        )  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # 드롭아웃 적용\n",
    "        y_embedding = self.dropout(y_embedding)\n",
    "\n",
    "        # 어텐션 맵을 저장할 텐서 초기화 (빈 텐서로 시작)\n",
    "        atten_decs = torch.tensor([]).to(self.device)\n",
    "        atten_enc_decs = torch.tensor([]).to(self.device)\n",
    "\n",
    "        # 제일 처음 입력은 y_embedding\n",
    "        decoder_output = y_embedding\n",
    "\n",
    "        # 각 decoder layer 통과\n",
    "        for layer in self.layers:\n",
    "            decoder_output, atten_dec, atten_enc_dec = layer(\n",
    "                decoder_output, enc_out, dec_mask, enc_dec_mask\n",
    "            )\n",
    "\n",
    "            if atten_map_save:\n",
    "                atten_decs = torch.cat([atten_decs, atten_dec[0].unsqueeze()])\n",
    "                atten_enc_decs = torch.cat(\n",
    "                    [atten_enc_decs, atten_enc_dec[0].unsqueeze()]\n",
    "                )\n",
    "\n",
    "        # Generator\n",
    "        decoder_output_linear = self.fc_out(decoder_output)\n",
    "\n",
    "        return decoder_output_linear, atten_decs, atten_enc_decs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfomer\n",
    "\n",
    "* encoder, decoder 조립\n",
    "* encoder, decoder mask 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_len,\n",
    "        n_layers,\n",
    "        pad_idx,\n",
    "        d_model=512,\n",
    "        d_ff=2048,\n",
    "        n_heads=8,\n",
    "        drop_p=0.1,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 입력 임베딩 레이어 정의\n",
    "        self.input_embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # 인코더, 디코더\n",
    "        self.encoder = Encoder(\n",
    "            self.input_embedding, max_len, n_layers, d_model, d_ff, n_heads, drop_p\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            self.input_embedding,\n",
    "            max_len,\n",
    "            n_layers,\n",
    "            d_model,\n",
    "            d_ff,\n",
    "            n_heads,\n",
    "            drop_p,\n",
    "            vocab_size,\n",
    "        )\n",
    "\n",
    "        # 멀티 헤드 어텐션 헤드 개수\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # 모든 모듈의 가중치를 Xavier 초기값으로 설정. 단, Layer Normalization이 가중치 제외.\n",
    "        for m in self.modules():\n",
    "            if (\n",
    "                hasattr(m, \"weight\") and m.weight.dim() > 1\n",
    "            ):  # 인풋 임베딩은 그대로 사용하기 위함\n",
    "                nn.init.xavier_uniform_(\n",
    "                    m.weight\n",
    "                )  # Xavier 초기화를 사용하여 가중치를 초기화\n",
    "\n",
    "        # 패딩 토큰 인덱스\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def make_enc_mask(self, src):\n",
    "        \"\"\"\n",
    "        인코더 마스크 생성\n",
    "        src : 입력 시퀀스, Shape: (batch_size, seq_len)\n",
    "        return : 인코더 마스크, Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        # 패딩 위치에 대해 True 값을 가지는 마스크 생성\n",
    "        enc_mask = (\n",
    "            (src == self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        )  # Shape: (batch_size, 1, 1, seq_len)\n",
    "\n",
    "        # 헤드 수만큼 마스크를 반복하여 확장\n",
    "        enc_mask = enc_mask.repeat(\n",
    "            1, self.n_heads, src.shape[1], 1\n",
    "        )  # Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "        \"\"\"\n",
    "    예시:\n",
    "    F F T T\n",
    "    F F T T\n",
    "    F F T T\n",
    "    F F T T\n",
    "    \"\"\"\n",
    "        return enc_mask\n",
    "\n",
    "    def make_dec_mask(self, target):\n",
    "        \"\"\"\n",
    "        디코더 마스크 생성\n",
    "        target : 목표 시퀀스, Shape: (batch_size, seq_len)\n",
    "        return : 디코더 마스크, Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        # 패딩 위치에 대해 True 값을 가지는 마스크 생성\n",
    "        target_pad_mask = (\n",
    "            (target.to(\"cpu\") == self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        )  # Shape: (batch_size, 1, 1, seq_len)\n",
    "\n",
    "        # 헤드 수만큼 마스크를 반복하여 확장\n",
    "        target_pad_mask = target_pad_mask.repeat(\n",
    "            1, self.n_heads, target.shape[1], 1\n",
    "        )  # Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "        \"\"\"\n",
    "    예시:\n",
    "    F F F T T\n",
    "    F F F T T\n",
    "    F F F T T\n",
    "    F F F T T\n",
    "    F F F T T\n",
    "    \"\"\"\n",
    "\n",
    "        # 현재 시점 이후의 위치에 대해 마스크 생성 (미래의 토큰을 마스킹)\n",
    "        target_future_mask = (\n",
    "            torch.tril(\n",
    "                torch.ones(\n",
    "                    target.shape[0], self.n_heads, target.shape[1], target.shape[1]\n",
    "                )\n",
    "            )\n",
    "            == 0\n",
    "        )  # Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "        \"\"\"\n",
    "    예시:\n",
    "    F T T T T\n",
    "    F F T T T\n",
    "    F F F T T\n",
    "    F F F F T\n",
    "    F F F F F\n",
    "    \"\"\"\n",
    "\n",
    "        # 패딩 마스크와 미래 마스크를 결합하여 최종 디코더 마스크 생성\n",
    "        dec_mask = (\n",
    "            target_pad_mask | target_future_mask\n",
    "        )  # Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "        \"\"\"\n",
    "    예시:\n",
    "    F T T T T\n",
    "    F F T T T\n",
    "    F F F T T\n",
    "    F F F F T\n",
    "    F F F F F\n",
    "    \"\"\"\n",
    "        return dec_mask\n",
    "\n",
    "    def make_enc_dec_mask(self, src, target):\n",
    "        \"\"\"\n",
    "        인코더-디코더 마스크 생성\n",
    "        src : 입력 시퀀스, Shape: (batch_size, seq_len)\n",
    "        target : 목표 시퀀스, Shape: (batch_size, seq_len)\n",
    "        return : 인코더-디코더 마스크, Shape: (batch_size, n_heads, seq_len, seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        # 패딩 위치에 대해 True 값을 가지는 마스크 생성 (인코더와 디코더 사이의 어텐션에 사용)\n",
    "        enc_dec_mask = (\n",
    "            (src == self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        )  # Shape: (batch_size, 1, 1, seq_len)\n",
    "\n",
    "        # 헤드 수만큼 마스크를 반복하여 확장\n",
    "        enc_dec_mask = enc_dec_mask.repeat(\n",
    "            1, self.n_heads, target.shape[1], 1\n",
    "        )  # Shape: (batch_size, n_heads, target_seq_len, src_seq_len)\n",
    "\n",
    "        \"\"\"\n",
    "    예시:\n",
    "    F F T T\n",
    "    F F T T\n",
    "    F F T T\n",
    "    F F T T\n",
    "    F F T T\n",
    "    \"\"\"\n",
    "        return enc_dec_mask\n",
    "\n",
    "    def forward(self, src, target):\n",
    "        \"\"\"\n",
    "        src : 입력 시퀀스, Shape: (batch_size, seq_len)\n",
    "        target : 목표 시퀀스, Shape: (batch_size, seq_len)\n",
    "        return : 모델 출력, 인코더 어텐션 맵, 디코더 어텐션 맵, 인코더-디코더 어텐션 맵\n",
    "        \"\"\"\n",
    "\n",
    "        # 인코더 마스크 생성\n",
    "        enc_mask = self.make_enc_mask(src)\n",
    "\n",
    "        # 디코더 마스크 생성\n",
    "        dec_mask = self.make_dec_mask(target)\n",
    "\n",
    "        # 인코더-디코더 마스크 생성\n",
    "        enc_dec_mask = self.make_enc_dec_mask(src, target)\n",
    "\n",
    "        # 인코더 통과\n",
    "        enc_out, atten_encs = self.encoder(src, enc_mask)\n",
    "\n",
    "        # 디코더 통과\n",
    "        out, atten_decs, atten_enc_decs = self.decoder(\n",
    "            target, enc_out, dec_mask, enc_dec_mask\n",
    "        )\n",
    "\n",
    "        return out, atten_encs, atten_decs, atten_enc_decs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>상황</th>\n",
       "      <th>Set Nr.</th>\n",
       "      <th>발화자</th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>A-1</td>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>B-1</td>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>A-2</td>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>B-2</td>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>2</td>\n",
       "      <td>A-1</td>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    대분류 소분류       상황  Set Nr.  발화자                            원문  \\\n",
       "0  비즈니스  회의  의견 교환하기        1  A-1   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1  비즈니스  회의  의견 교환하기        1  B-1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  비즈니스  회의  의견 교환하기        1  A-2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3  비즈니스  회의  의견 교환하기        1  B-2   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4  비즈니스  회의  의견 교환하기        2  A-1   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"../../data/nlp/kor_eng_translate.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 7), (16000, 7), (20000, 7))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_data.shape, valid_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('음료수는 콜라, 사이다 중에 어떤 걸로 하시겠어요?',\n",
       " 'Which drink would you like out of coke and soda?')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.data.iloc[idx, self.data.columns.get_loc(\"원문\")],\n",
    "            self.data.iloc[idx, self.data.columns.get_loc(\"번역문\")],\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_data)\n",
    "valid_dataset = CustomDataset(valid_data)\n",
    "test_dataset = CustomDataset(test_data)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "val_DL = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "test_DL = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer  # MT: Machine Translation\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15004, 37141,   603,     0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전학습된 (pretrained) 모델의 성능을 알아보자\n",
    "max_len = 128  # 기본은 512인데, 너무 길면 gpu에 부담됨 ㅎㅎ;\n",
    "\n",
    "input_text = \"김탱구\"\n",
    "\n",
    "# tokenizer.encode : 텍스트 -> 단어 토큰화-> 정수로 바꿔줌.\n",
    "src_tokens = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65000, 16456,  1220,  8199, 13936,     0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_tokens = model.generate(src_tokens, max_new_tokens=max_len)\n",
    "translated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kim Tang Gu'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수를 텍스트로 바꾸는걸 뭐라고 해찌? decode\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 주말은 바쁘고, 다음다음 주 주말 어때?  ==>  This weekend I am busy, so how about next next weekend?\n",
      "죄송한 건 됐고 이거 어떻게 하실 건지 물었잖아요?  ==>  That is enough apologies, I asked what you will do about this?\n",
      "근데, 아무리 봐도 이 주변에는 주택 밖에 안 보이는데.  ==>  But, I can only see houses around here.\n"
     ]
    }
   ],
   "source": [
    "# src에는 한국어(원문), trg에는 영어(번역)\n",
    "src_texts, trg_texts = next(iter(train_DL))\n",
    "print(src_texts[0], \" ==> \", trg_texts[0])\n",
    "print(src_texts[1], \" ==> \", trg_texts[1])\n",
    "print(src_texts[2], \" ==> \", trg_texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁이번', '▁주말', '은', '▁바쁘', '고', ',', '▁다음', '다음', '▁주', '▁주말', '▁어때', '?']\n",
      "['▁', 'Th', 'is', '▁w', 'eek', 'end', '▁I', '▁', 'am', '▁b', 'us', 'y', ',', '▁so', '▁h', 'ow', '▁about', '▁n', 'ext', '▁n', 'ext', '▁w', 'eek', 'end', '?']\n"
     ]
    }
   ],
   "source": [
    "src_tokens = tokenizer.tokenize(src_texts[0])\n",
    "trg_tokens = tokenizer.tokenize(trg_texts[0])\n",
    "\n",
    "print(src_tokens)\n",
    "print(trg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
