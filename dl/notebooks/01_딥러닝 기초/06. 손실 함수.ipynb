{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeklsA8SiOaePk6lYheeAn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 손실함수\n","머신러닝 모델의 성능 지표(metric)\n","- Accuracy\n","- F1-Score\n","- Precision, Recall,\n","- ROC - AUC\n","- 추가적으로 딥러닝에서는 Loss라는 지표를 우선시 한다.언제? 훈련 할 때"],"metadata":{"id":"W1LefL1cpX0p"}},{"cell_type":"markdown","source":["# 평균 제곱 오차 ( Mean Squared Error )\n","신경망에서의 MSE\n","$$\n","MSE = \\frac{1}{2}\\sum_k(y_k-t_k)^2\n","$$\n","\n","인간이 신경망을 공부할 때 사용하는 공부용 MSE 입니다..\n","\n","* $y_k$ : 신경망의 예측값\n","* $t_k$ : 정답 레이블\n","* $k$ : 출력층의 뉴런 개수\n","  * `강아지, 고양이, 말을 예측 하면` $k$는 3 - `클래스는 [0, 1, 2]`\n","  * MNIST 손글씨 데이터 셋이면 $k$는 10 - `클래스는 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n","\n","----------\n","* 보통 신경망에서는 `MSE`를 잘 쓰지 않고 `Cross Entropy Error`를 활용\n","  * `MSE`는 신경망으로 회귀를 할 때 많이 사용\n","* `MSE`를 배우는 이유는 말 그대로 `loss`에 대한 이해를 하기 위함\n","* `MSE`는 신경망을 우리가 공부 할 때 개념을 익히는 데에 좋다. ( 실무에서는 사용 잘 안한다. )\n","* 정상적인 $\\frac{1}{n}$을 사용하지 않고 $\\frac{1}{2}$을 사용한 이유는\n","  * `MSE`를 미분 했을 때 남는게 순수한 오차라고 할 수 있는 $(y-t)$만 남기 때문에"],"metadata":{"id":"lPDpkKb8pdxh"}},{"cell_type":"code","source":["import numpy as np\n","\n","# y : 예측\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","\n","# t : 타깃\n","t = np.array([0,      0,   1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2라는 이야기 이다. 클래스의 개수만큼 One Hot Encoding이 되어있는 상태"],"metadata":{"id":"22okor7GqCiP","executionInfo":{"status":"ok","timestamp":1725866729997,"user_tz":-540,"elapsed":444,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 각 클래스 별 순수한 오차\n","y - t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iObjIqmMrDex","executionInfo":{"status":"ok","timestamp":1725866766481,"user_tz":-540,"elapsed":499,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"b9aeb6b4-fba4-4640-8836-ee527f50a5b7"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.1 ,  0.05, -0.4 ,  0.  ,  0.05,  0.1 ,  0.  ,  0.1 ,  0.  ,\n","        0.  ])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["def mean_squared_error(y, t):\n","  return np.sum((y - t)**2) * 0.5"],"metadata":{"id":"hDxe8hpnrOwP","executionInfo":{"status":"ok","timestamp":1725866862538,"user_tz":-540,"elapsed":477,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 모델이 정답을 2로 추정 했을 때의 예측 오차(2로 예측한 확률이 0.6)\n","mean_squared_error(y, t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii7QsYEQrmNs","executionInfo":{"status":"ok","timestamp":1725866903247,"user_tz":-540,"elapsed":509,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"b98c6032-1e90-494e-8187-1c328c27a848"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.09750000000000003"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.6) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.8) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.1) : {:.3f}\".format(mean_squared_error(y, t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNh0OIIQrv79","executionInfo":{"status":"ok","timestamp":1725867065632,"user_tz":-540,"elapsed":465,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"e606f41f-1288-4c4e-efba-d91f8971f352"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 MSE값(0.6) : 0.098\n","정답을 2로 추정했을 때의 MSE값(0.8) : 0.027\n","정답을 2로 추정했을 때의 MSE값(0.1) : 0.657\n"]}]},{"cell_type":"markdown","source":["# 교차 엔트로피 오차( Cross Entropy Error )\n","$$\n","CEE = -\\sum_{k}t_k\\log{y_k}\n","$$\n","\n","* $t_k$는 `One Hot Encoding`이 되어있는 상태\n","* $k$는 클래스의 개수\n","* 정답 레이블의 소프트맥스의 결과가 0.6이면 $-\\log{0.6}$을 구한것과 똑같다."],"metadata":{"id":"kMhbf791sWWv"}},{"cell_type":"code","source":["def cross_entropy_error(y, t):\n","  delta = 1e-7 # epsilon이라고도 합니다. log 0이 되는 것을 방지\n","  return -np.sum(t * np.log(y + delta))"],"metadata":{"id":"1kdnJ7emsnNc","executionInfo":{"status":"ok","timestamp":1725867488475,"user_tz":-540,"elapsed":1045,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["t = np.array([0, 0, 1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2\n","\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.6) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.8) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.1) : {:.3f}\".format(cross_entropy_error(y, t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfW2nR3OtweG","executionInfo":{"status":"ok","timestamp":1725867498261,"user_tz":-540,"elapsed":676,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"7b4ce6d4-d448-41de-9ddf-d4114bba925c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 CEE값(0.6) : 0.511\n","정답을 2로 추정했을 때의 CEE값(0.8) : 0.223\n","정답을 2로 추정했을 때의 CEE값(0.1) : 2.303\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1L-bUE29uBOe"},"execution_count":null,"outputs":[]}]}